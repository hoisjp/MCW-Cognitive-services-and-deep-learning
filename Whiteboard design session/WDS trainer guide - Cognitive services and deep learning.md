<!--
![Microsoft Cloud Workshops](https://github.com/Microsoft/MCW-Template-Cloud-Workshop/raw/master/Media/ms-cloud-workshop.png "Microsoft Cloud Workshops")

<div class="MCWHeader1">
Cognitive services and deep learning
</div>

<div class="MCWHeader2">
Whiteboard design session trainer guide
</div>

<div class="MCWHeader3">
December 2019
</div>

Information in this document, including URL and other Internet Web site references, is subject to change without notice. Unless otherwise noted, the example companies, organizations, products, domain names, e-mail addresses, logos, people, places, and events depicted herein are fictitious, and no association with any real company, organization, product, domain name, e-mail address, logo, person, place or event is intended or should be inferred. Complying with all applicable copyright laws is the responsibility of the user. Without limiting the rights under copyright, no part of this document may be reproduced, stored in or introduced into a retrieval system, or transmitted in any form or by any means (electronic, mechanical, photocopying, recording, or otherwise), or for any purpose, without the express written permission of Microsoft Corporation.

Microsoft may have patents, patent applications, trademarks, copyrights, or other intellectual property rights covering subject matter in this document. Except as expressly provided in any written license agreement from Microsoft, the furnishing of this document does not give you any license to these patents, trademarks, copyrights, or other intellectual property.

The names of manufacturers, products, or URLs are provided for informational purposes only, and Microsoft makes no representations and warranties, either expressed, implied, or statutory, regarding these manufacturers or the use of the products with any Microsoft technologies. The inclusion of a manufacturer or product does not imply endorsement of Microsoft of the manufacturer or product. Links may be provided to third-party sites. Such sites are not under the control of Microsoft and Microsoft is not responsible for the contents of any linked site or any link contained in a linked site, or any changes or updates to such sites. Microsoft is not responsible for webcasting or any other form of transmission received from any linked site. Microsoft is providing these links to you only as a convenience, and the inclusion of any link does not imply endorsement of Microsoft of the site or the products contained therein.

© 2019 Microsoft Corporation. All rights reserved.

Microsoft and the trademarks listed at <https://www.microsoft.com/en-us/legal/intellectualproperty/Trademarks/Usage/General.aspx> are trademarks of the Microsoft group of companies. All other trademarks are the property of their respective owners.

**Contents**

-->
<!-- TOC -->
<!--

- [Trainer information](#trainer-information)
  - [Role of the trainer](#role-of-the-trainer)
  - [Whiteboard design session flow](#whiteboard-design-session-flow)
  - [Before the whiteboard design session: How to prepare](#before-the-whiteboard-design-session-how-to-prepare)
  - [During the whiteboard design session: Tips for an effective whiteboard design session](#during-the-whiteboard-design-session-tips-for-an-effective-whiteboard-design-session)
- [Cognitive services and deep learning whiteboard design session student guide](#cognitive-services-and-deep-learning-whiteboard-design-session-student-guide)
  - [Abstract and learning objectives](#abstract-and-learning-objectives)
  - [Step 1: Review the customer case study](#step-1-review-the-customer-case-study)
    - [Customer situation](#customer-situation)
    - [Customer needs](#customer-needs)
    - [Customer objections](#customer-objections)
    - [Infographic for common scenarios](#infographic-for-common-scenarios)
  - [Step 2: Design a proof of concept solution](#step-2-design-a-proof-of-concept-solution)
  - [Step 3: Present the solution](#step-3-present-the-solution)
  - [Wrap-up](#wrap-up)
  - [Additional references](#additional-references)
- [Cognitive services and deep learning whiteboard design session trainer guide](#cognitive-services-and-deep-learning-whiteboard-design-session-trainer-guide)
  - [Step 1: Review the customer case study](#step-1-review-the-customer-case-study-1)
  - [Step 2: Design a proof of concept solution](#step-2-design-a-proof-of-concept-solution-1)
  - [Step 3: Present the solution](#step-3-present-the-solution-1)
  - [Wrap-up](#wrap-up-1)
  - [Preferred target audience](#preferred-target-audience)
  - [Preferred solution](#preferred-solution)
  - [Checklist of preferred objection handling](#checklist-of-preferred-objection-handling)
  - [Customer quote (to be read back to the attendees at the end)](#customer-quote-to-be-read-back-to-the-attendees-at-the-end)

-->
<!-- /TOC -->
<!-- 

# Trainer information

Thank you for taking time to support the whiteboard design sessions as a trainer!

## Role of the trainer

An amazing trainer:

- Creates a safe environment in which learning can take place.

- Stimulates the participant's thinking.

- Involves the participant in the learning process.

- Manages the learning process (on time, on topic, and adjusting to benefit participants).

- Ensures individual participant accountability.

- Ties it all together for the participant.

- Provides insight and experience to the learning process.

- Effectively leads the whiteboard design session discussion.

- Monitors quality and appropriateness of participant deliverables.

- Effectively leads the feedback process.

## Whiteboard design session flow

Each whiteboard design session uses the following flow:

**Step 1: Review the customer case study (15 minutes)**

**Outcome**

Analyze your customer's needs.

- Customer's background, situation, needs and technical requirements

- Current customer infrastructure and architecture

- Potential issues, objectives and blockers

**Step 2: Design a proof of concept solution (60 minutes)**

**Outcome**

Design a solution and prepare to present the solution to the target customer audience in a 15-minute chalk-talk format.

- Determine your target customer audience.

- Determine customer's business needs to address your solution.

- Design and diagram your solution.

- Prepare to present your solution.

**Step 3: Present the solution (30 minutes)**

**Outcome**

Present solution to your customer:

- Present solution

- Respond to customer objections

- Receive feedback

**Wrap-up (15 minutes)**

- Review preferred solution

## Before the whiteboard design session: How to prepare

Before conducting your first whiteboard design session:

- Read the Student guide (including the case study) and Trainer guide.

- Become familiar with all key points and activities.

- Plan the point you want to stress, which questions you want to drive, transitions, and be ready to answer questions.

- Prior to the whiteboard design session, discuss the case study to pick up more ideas.

- Make notes for later.

## During the whiteboard design session: Tips for an effective whiteboard design session

**Refer to the Trainer guide** to stay on track and observe the timings.

**Do not expect to memorize every detail** of the whiteboard design session.

When participants are doing activities, you can **look ahead to refresh your memory**.

- **Adjust activity and whiteboard design session pace** as needed to allow time for presenting, feedback, and sharing.

- **Add examples, points, and stories** from your own experience. Think about stories you can share that help you make your points clearly and effectively.

- **Consider creating a "parking lot"** to record issues or questions raised that are outside the scope of the whiteboard design session or can be answered later. Decide how you will address these issues, so you can acknowledge them without being derailed by them.

***Have fun**! Encourage participants to have fun and share!*

**Involve your participants.** Talk and share your knowledge but always involve your participants, even while you are the one speaking.

**Ask questions** and get them to share to fully involve your group in the learning process.

**Ask first**, whenever possible. Before launching into a topic, learn your audience's opinions about it and experiences with it. Asking first enables you to assess their level of knowledge and experience, and leaves them more open to what you are presenting.

**Wait for responses**. If you ask a question such as, "What's your experience with (fill in the blank)?" then wait. Do not be afraid of a little silence. If you leap into the silence, your participants will feel you are not serious about involving them and will become passive. Give participants a chance to think, and if no one answers, patiently ask again. You will usually get a response.

# Cognitive services and deep learning whiteboard design session student guide

## Abstract and learning objectives

In this whiteboard design session, you will work with a group to design a solution which combines both pre-built artificial intelligence (AI) in the form of various Cognitive Services, with custom AI in the form of services built and deployed with Azure Machine Learning service. You will learn to create intelligent solutions atop unstructured text data by designing and implementing a text analytics pipeline. You will discover how to build a binary classifier using a recurrent neural network that can be used to classify the textual data, as well as how to deploy multiple kinds of predictive services using Azure Machine Learning service and learn to integrate with the Computer Vision API and the Text Analytics API from Cognitive Services.

At the end of this whiteboard design session, you will be better able to design solutions leveraging the Azure Machine Learning service and Cognitive Services.

## Step 1: Review the customer case study

**Outcome**

Analyze your customer's needs.

Timeframe: 15 minutes

Directions:  With all participants in the session, the facilitator/SME presents an overview of the customer case study along with technical tips.

1. Meet your table participants and trainer.

2. Read all of the directions for steps 1-3 in the student guide.

3. As a table team, review the following customer case study.

### Customer situation

Contoso Ltd is a large corporation, headquartered in the United States that provides insurance packages for U.S. consumers. Its products include accident and health insurance, life insurance, travel, home, and auto coverage.

Contoso is looking to build a next-generation platform for its insurance products and had identified claims processing as the first area in which they would like to focus their efforts. Currently customers submit a claim using either the website, their mobile app or by speaking with a live agent.

A claim includes the following information:

- Information about the insured (contact information, policy number, etc.)

- Free text responses describing the claim (details of what happened, what was affected, the conditions in which it occurred)

- Photographs that support the claim (photos of the insured object before the event, photos of the damage or stolen items, etc.)

When an agent (an employee or contractor of Contoso) is processing a claim, there are multiple challenges that add significantly to the cost, including the significant time it takes for an agent to read through and process the content submitted with each claim, as well as the difficulty they have in finding particular claim artifacts when returning to a claim after a while. While each claim is stored in a database, the details about the claim, including the free text responses and supporting photos, are stored as opaque attachments that are not searchable - meaning agents typically pull up the claim by the claim number or the insured's contact information and then must manually read through the attachments.

Also, there are some common challenges that Contoso is hoping they could automate away. According to Francine Fischer, CIO, there are two sets of issues where they envision amplifying the capabilities of their agents with AI.

One set of such issues deals with the free text responses. The first issue Contoso identified is that each claim detail should be automatically classified as either home or auto based on the text. This classification would be displayed in the claim summary, so an agent can quickly assess whether they are dealing with purely a home claim, an auto claim or a claim that has a mixture of the two.

The second issue is Contoso would like to experiment applying sentiment analysis to the claim text. They know most customers are either  factual in their description (a neutral sentiment) or slightly unhappy (a more negative sentiment), but believe that a negative sentiment can be an indicator to claim text that involves a more severe situation, which might warrant an expedited review by an agent.

The third issue with the free text is that some of the responses are long. When agents are shifting between claims, it can be hard for them to recall which response had the details for which they are looking. Contoso would like to experiment with an automatic summarization of long claims that produces a summary of about 30 words in length. This summarization would enable the agent to get the gist before having to read the full claim and can quickly remind themselves of the claim when revisiting it.

The next set of issues where they would like to amplify the capabilities of their agents have to deal with extracting information from the photos submitted to increase their searchability. The first item they would like to address is providing automatic captions describing the contents of the photo. Second, they would like to automatically apply tags that describe the content of the photo. Third, the solution should try to pull out any text that appears in the image. Taken together, solving these items can reduce the amount of data entry an agent has to do, while simultaneously increasing the searchability for content present in photos.

As a final step, they would like to organize the information extracted from photos, tying it together with the results of processing the free text responses into a solution that is easily searchable and stays up to date as new claim information surfaces.

As a first step towards their bigger goals, Contoso would like to build a proof of concept (PoC) for an intelligent solution that could automate all the above. They would like to build this PoC to build upon their claims submission solution they already have running in Azure (which consists of a Web App for claims submission and a SQL Database for claim storage). They believe this might be possible using AI, machine learning or deep learning and would like to build a proof of concept to understand just how far they can go using these technologies.

### Customer needs

1. We receive a lot of useful information in the free text responses, but because they can be long, agents sometimes skip over them and miss vital details or spend too much time looking for a particular detail when returning to a claim. We aren't certain this can be automated, but we would like to have a standardized process that identifies the key entities in a claim and pulls them out into a separate list that agents can more easily review, and then view the entity in the context of the claim.

2. We need a solution that can "look" at a photo and give us a description of the photos contents and tag the photos with keywords, so agents can more easily find and refer to the photo later.

3. We are looking to amplify the capabilities of our agents and improve their claims processing capabilities - not replace them. We want a solution that does the same.

### Customer objections

1. We are skeptical about all the hype surrounding these "AI" solutions. It's hard to know what is feasible versus what is not possible with today's technology and Azure.

2. We know that are both pre-built AI and custom AI options available. We are confused as to when to choose one over the other.

3. We expect some part of our solution would require deep learning. Do you have any prescriptive guidance on how we might choose between investing in learning and using TensorFlow or the Microsoft Cognitive Toolkit (CNTK)?

### Infographic for common scenarios

![In the Training a classification model with text diagram, Document labels points to Supervised ML or DL Algorithm, which points to Classification Model. Documents points to Text Normalization, which points to Feature Extraction, which points to Supervised ML or DL Algorithm. Vectors points to a table of words and percentages.](images/Whiteboarddesignsessiontrainerguide-CognitiveServicesanddeeplearningimages/media/image2.png "Training a classification model with text diagram")

![The Predicting a classification from text diagram has Documents, which points to Text Normalization, which points to Feature Extraction, which points to Classification Model, which points to Document Labels. Vectors points to a table of words and percentages.](images/Whiteboarddesignsessiontrainerguide-CognitiveServicesanddeeplearningimages/media/image3.png "Predicting a classification from text diagram")

## Step 2: Design a proof of concept solution

**Outcome**

Design a solution and prepare to present the solution to the target customer audience in a 15-minute chalk-talk format.

Timeframe: 60 minutes

**Business needs**

Directions: With all participants at your table, answer the following questions and list the answers on a flip chart:

1. Who should you present this solution to? Who is your target customer audience? Who are the decision makers?

2. What customer business needs do you need to address with your solution?

**Design**

Directions: With all participants at your table, respond to the following questions on a flip chart:

_High-level architecture_

1. Without getting into the details (the following sections will address the details), diagram your initial vision for handling the top-level requirements for processing the claims textual data, photos, and enabling search. You will refine this diagram as you proceed.

_Classifying claim-text data_

1. What is the general pipeline for approaching the training of text analytic models such as this? What are the general steps you need to take to prepare the text data for performing tasks like classification?

2. What data would they need to train the model?

3. Contoso want to understand some of the common approaches to handle texts for machine learning? Is there a recommended approach to dealing with long descriptive texts that are typically found in claims data?

4. Contoso understands they should use a classification algorithm for this problem. They have asked if a Deep Neural Network could be trained against the text to recognize home or auto classifications. Could they use a DNN for this?

5. For this scenario, Contoso has indicated an interest in using TensorFlow, but is concerned about the complexity of jumping right in. They are wondering if Keras would provide an easier framework they could use as a stepping stone to the full blown TensorFlow, that would enable them to build TensorFlow compatible models so that they can "graduate" to using TensorFlow when the team is ready?

6. What would a LSTM recurrent neural network that performs this classification look like? Show a snippet of a single layer of an unrolled LSTM network, and the binary classification output at the last step of the network.

7. Assuming they will be using a LSTM recurrent neural network to train the classifier using Keras, pseudo code the code you would write to construct the network you just illustrated.

8. Next, pseudo code how they would define the optimizer, loss function and fit the model to the vectorized data and the labels.

9. With the trained model in hand, pseudo code how the model would be used to predict the class of a given claim text. What would the output of the prediction be? How would you interpret the value?

10. Describe at a high level, how you would deploy this trained model, so it is available as a web service that can be integrated with the rest of the solution.

_Identifying free-text sentiment_

1. How would you recommend Contoso identify the sentiment in the free-response text provided associated with a claim? Would this require you to build a custom AI model? Is there a pre-built AI service you could use?

2. For the solution you propose, what is the range of value of the sentiment score and how would you interpret that value?

_Summarizing claim text_

1. The team at Contoso has heard about a Python library called Gensim that has a summarize function. Given an input of text, it can extract a summary of the desired length. Contoso would like their PoC to implement its summarization functionality initially using Gensim. However, the process they follow to deploy the summarization capability should also enable them to replace the use of Gensim with another library or with the use of their own custom trained models if desired down the road. Describe how Contoso should deploy the summarization service to meet these requirements?

2. Can they deploy a predictive web service to Azure Machine Learning service that does not utilize an external model (as in the case with Gensim) or would support an unsupervised approach?

_Captions, tags and "reading" images_

1. How would you recommend Contoso implement support for automatically creating captions for the claim photos? Similarly, how would they automatically generate tags? Would this require you to build a custom AI model? Is there a pre-built AI service you could use?

2. Describe the flow of processing of an image as input; what value is returned by each component in your proposed solution for captioning and tagging images?

3. How would you recommend Contoso implement support for "reading" any text that appears within an image, so that it could be searched later? Would this require you to build a custom AI model? Is there a pre-built AI service you could use?

4. Describe the flow of processing of an image as input; what value is returned by each component in your proposed solution for "reading" images?

_Enabling search_

1. What service would you recommend Contoso leverage to enable greater searchability over the claim data, inclusive of the new data fields created by your text processing and image processing components?

2. Would they be able to keep their claims data in the existing database and layer in this search capability? If so, explain how.

**Prepare**

Directions: With all participants at your table:

1. Identify any customer needs that are not addressed with the proposed solution.

2. Identify the benefits of your solution.

3. Determine how you will respond to the customer's objections.

Prepare a 15-minute chalk-talk style presentation to the customer.

## Step 3: Present the solution

**Outcome**

Present a solution to the target customer audience in a 15-minute chalk-talk format.

Timeframe: 30 minutes

**Presentation**

Directions:

1. Pair with another table.

2. One table is the Microsoft team and the other table is the customer.

3. The Microsoft team presents their proposed solution to the customer.

4. The customer makes one of the objections from the list of objections.

5. The Microsoft team responds to the objection.

6. The customer team gives feedback to the Microsoft team.

7. Tables switch roles and repeat Steps 2-6.

## Wrap-up

Timeframe: 15 minutes

Directions: Tables reconvene with the larger group to hear the facilitator/SME share the preferred solution for the case study. 

## Additional references

|                                                       |                                                                                                   |
| ----------------------------------------------------- | ------------------------------------------------------------------------------------------------- |
| **Description**                                       | **Links**                                                                                         |
| Azure Machine Learning service                        | <https://docs.microsoft.com/en-us/azure/machine-learning/service/overview-what-is-azure-ml>       |  |
| Deploying Web Services                                | <https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-deploy-and-where> |
| Overview of Keras                                   | <https://keras.io/> |
| Overview of TensorFlow                                | <https://www.tensorflow.org/> |
| Term Frequency-Inverse Document Frequency (TF-IDF) vectorization | <https://en.wikipedia.org/wiki/Tf-idf> |
| GloVe: Global Vectors for Word Representation | <https://nlp.stanford.edu/projects/glove/>  |
| Research Paper: "GloVe: Global Vectors for Word Representation" | <https://nlp.stanford.edu/pubs/glove.pdf>  |
| Word2vec word embeddings | <https://en.wikipedia.org/wiki/Word2vec>  |
| Overview of the Computer Vision API Cognitive Service | <https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/home>                  |
| Overview of the Text Analytics API Cognitive Service  | <https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/overview>               |

# Cognitive services and deep learning whiteboard design session trainer guide

## Step 1: Review the customer case study

- Check in with your table participants to introduce yourself as the trainer.

- Ask, "What questions do you have about the customer case study?"

- Briefly review the steps and timeframes of the whiteboard design session.

- Ready, set, go! Let the table participants begin.

## Step 2: Design a proof of concept solution

- Check in with your tables to ensure that they are transitioning from step to step on time.

- Provide some feedback on their responses to the business needs and design.

  - Try asking questions first that will lead the participants to discover the answers on their own.

- Provide feedback for their responses to the customer's objections.

  - Try asking questions first that will lead the participants to discover the answers on their own.

## Step 3: Present the solution

- Determine which table will be paired with your table before Step 3 begins.

- For the first round, assign one table as the presenting team and the other table as the customer.

- Have the presenting team present their solution to the customer team.

  - Have the customer team provide one objection for the presenting team to respond to.

  - The presentation, objections, and feedback should take no longer than 15 minutes.

  - If needed, the trainer may also provide feedback.

## Wrap-up

- Have the table participants reconvene with the larger session group to hear the facilitator/SME share the following preferred solution.

## Preferred target audience

Francine Fischer, CIO of Contoso Ltd.

The primary audience is the business decision makers and technology decision makers. From the case study scenario, this would include the Director of Analytics. Usually we talk to the infrastructure managers, who report to the chief information officers (CIOs), or to application sponsors (like a vice president \[VP\] line of business \[LOB\], or chief marketing officer \[CMO\]), or to those that represent the business unit IT or developers that report to application sponsors.

## Preferred solution

_High-level architecture_

1. Without getting into the details (the following sections will address the details), diagram your initial vision for handling the top-level requirements for processing the claims textual data, photos, and enabling search. You will refine this diagram as you proceed.

After speaking with its team at Microsoft, Contoso decided to design their PoC solution in Azure. They would continue to use the web app and SQL database that they already have running in Azure to handle claim submissions. They could build a claim enrichment pipeline by invoking a sequence of Azure Functions, where each of the coordinates calls to various AI-powered services.

 ![The High-level architectural solution begins with a Claim, which points to Jupyter notebook. Jupyter then points to Computer Vision, Text Analytics, and Containerized Services, which includes a Classification Service and a Summary Service that both processes claim text.](images/Whiteboarddesignsessiontrainerguide-CognitiveServicesanddeeplearningimages/media/image4.jpg "High-level architectural solution")

The claim image processing functions would invoke the Computer Vision Cognitive Service for automatically creating the caption and the tags from any supplied claim images. A mixture of pre-built AI, in the form of Cognitive Services and custom AI in the form of Azure ML services, would be used to process the claim text. The models used for processing the claims text would be trained in Azure Databricks notebooks. These models could also then be directly deployed from Azure Databricks using the Azure Machine Learning Service Python SDK. Azure Functions would be used to coordinate the calls to the classifications and summary AI services, which would run as containerized web services in Azure Container Service, while the Text Analytics API could be invoked directly to provide a sentiment score for each claim text.

 ![In the Claim image processing diagram, Function (claim text processing) points to Sentiment, classification and summary, Text Analytics, and Containerized services comprised of Classification Service and Summary Service.](images/Whiteboarddesignsessiontrainerguide-CognitiveServicesanddeeplearningimages/media/image5.png "Claim image processing diagram")

Once all claim processing has completed, one final Azure Function could be used to insert the complete claim document into Azure Search. The inserted document would contain the claim number as a field so that it could always be tied back to the record store in Azure SQL Database.

_Classifying claim text data_

1. What is the general pipeline for approaching the training of text analytic models such as this? What are the general steps you need to take to prepare the text data for performing tasks like classification?

    ![In the high-level steps for training a classification model with text diagram, Document labels points to Supervised ML or DL Algorithm, which points to Classification Model. Documents points to Text Normalization, which points to Feature Extraction, which points to Supervised ML or DL Algorithm.](images/Whiteboarddesignsessiontrainerguide-CognitiveServicesanddeeplearningimages/media/image6.png "High-level steps for training a classification model with text")

    As the above diagram illustrates, the general pipeline begins by pre-processing or normalizing the text. This step typically includes tasks such as breaking the text into sentence and word tokens, standardizing the spelling of words, and removing overly common words (called stop words). The output of this phase is typically a multi-dimensional array consisting of an array of documents, each having an array of sentences, with each sentence having its own array of words. The next step is feature extraction, which creates a numeric representation of the textual documents. During feature extraction, a "vocabulary" of unique words is identified, and each word becomes a column in the output. Each row represents a document. The value in each cell is typically a measure of the relative importance of that word in the document, where if a word from the vocabulary does not appear, then that cell has a zero value in that column. This approach enables machine learning algorithms, which operate against arrays of numbers, to also operate against text. Deep learning algorithms operate on tensors, which are also vectors (or arrays of numbers), so this approach is also valid for preparing text for use with a deep learning algorithm.

2. What data would they need to train the model?

    Contoso would need to have a certain amount of historical claim text and have it labeled as home or auto to train a model.

3. Contoso want to understand some of the common approaches to handle texts for machine learning? Is there a recommended approach to dealing with long descriptive texts that are typically found in claims data?

    Machine learning models requires numeric data as inputs. Thus, when you are working with text, as part of feature extraction, you convert words or sentences in text into numeric vector representation. There are several approaches to vectorize textual data, that include approaches like [Term Frequency-Inverse Document Frequency  (TF-IDF) vectorization](https://en.wikipedia.org/wiki/Tf-idf), or use of word embedding like [Word2vec](https://en.wikipedia.org/wiki/Word2vec) or [Global Vectors (GloVe)](https://nlp.stanford.edu/pubs/glove.pdf). 

    The approach of TF-IDF is to give less important to words that are common in most documents and giver higher importance to words that appears more frequently in fewer documents. Thus TF-IDF assigns weights to words that signify their relevance in the documents. There are some disadvantages to the TF-ID approach, most notably it makes no use of semantic similarities between words.

    The use of embedding to represent words or sentences is considered the-state-of-the art in NLP field. Most commonly used word embedding with DNN is either Word2vec or GloVe. Both Word2vec and GloVe are known to perform similarly, with GloVe claiming to outperform its peers on similarity tasks and named entity recognition.

    In the scenario, given the descriptive nature of the claims data, it is recommended that they use pretrained GloVe word embedding from [nlp.stanford.edu](https://nlp.stanford.edu/projects/glove/) for vector representation of words.

4. Contoso understands they should use a classification algorithm for this problem. They have asked if a Deep Neural Network could be trained against the text to recognize home or auto classifications? Could they use a DNN for this?

    Yes, they could use a type of DNN called the Long Short-Term Memory (LSTM) recurrent neural network that is shown to work well for text classification problems, especially when used in conjunction with word embedding such as GloVe for word vectorization.

5. For this scenario, Contoso has indicated an interest in using TensorFlow, but is concerned about the complexity of jumping right in. They are wondering if Keras would provide an easier framework they could use as a stepping stone to the full-blown TensorFlow, which would enable them to build TensorFlow compatible models so that they can "graduate" to using TensorFlow when the team is ready.

    TensorFlow is a robust framework for performing machine learning, including building neural networks. The Keras library builds upon TensorFlow and provides an easy-to-use and understand high-level API for implementing deep neural networks, complete with tutorials and examples. Models built with Keras are TensorFlow models, so if they choose to move fully towards the lower level TensorFlow API's, then they could do so without having to re-create the models.

6. What would a LSTM recurrent neural network that performs this classification look like? Show a snippet of a single layer of an unrolled LSTM network, and the binary classification output at the last step of the network.

    ![The figure shows a snippet of a single layer of an unrolled LSTM network, and the binary classification output layer at the last step of the network.](images/Whiteboarddesignsessiontrainerguide-CognitiveServicesanddeeplearningimages/media/lstm.png "Unrolled LSTM network")

7. Assuming they will be using a LSTM recurrent neural network to train the classifier using Keras, pseudo code the code you would write to construct the network you just illustrated.

    ```python
    model = Sequential()

    model.add(embedding_layer)

    model.add(LSTM(100, ..., ...))

    model.add(Dense(2))

    model.add(Activation('sigmoid'))
    ```

8. Next, pseudo code how they would define the optimizer, loss function and fit the model to the vectorized data and the labels.

    ```python
    opt = keras.optimizers.Adam(lr = ...)

    model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['accuracy'])

    model.fit(X_train, y_train, epochs = ..., batch_size = ..., validation_data = ...)
    ```

9. With the trained model in hand, pseudo code how the model would be used to predict the class of a given claim text. What would the output of the prediction be? How would you interpret the value?

    ```python
    test_claim = ['I crashed my car into a pole.']

    pred = model.predict(test_claim)
    ```

    The output of pred is an array of the confidence that label is a 0 or a 1. For example:

    ```python
    array([ [0.22, 0.78] ])
    ```

    Could be interpreted to indicate that a prediction of 1 ("auto insurance claim") with a confidence of 78%.

10. Describe at a high level, how you would deploy this trained model so it is available as a web service that can be integrated with the rest of the solution? What Azure Service(s) would be involved?

     The trained model is saved to a file. Then this file is loaded by web service code that re-creates the model architecture and loads the model weights. The web service code can then run classifications using the model. You could deploy this service using Azure Machine Learning service, which would capture the web service in a container, and then deploy the container to Azure Container Service where it can be invoked by any REST client.

_Identifying free-text sentiment_

1. How would you recommend Contoso identify the sentiment in the free-response text provided associated with a claim? Would this require you to build a custom AI model is there a pre-built AI service you could use?

    Contoso should use the Text Analytics API from Cognitive Services for scoring the sentiment of the claim text. By doing so, they would not have to build or train a custom model, nor have the requirement of having the data to do so.

2. For the solution you propose, what is the range of value of the sentiment score and how would you interpret that value?

    The Text Analytics API returns values in the range of 0 to 1. A value closer to 0 is interpreted as strongly negative sentiment, near 0.5 as neutral sentiment and closer to 1 as strongly positive sentiment.

_Summarizing claim text_

1. The team at Contoso has heard about a Python library called Gensim that has a summarize function. Given an input of text, it is capable of extracting a summary of the desired length. Contoso would like their PoC to implement its summarization functionality initially using Gensim. However, the process they follow to deploy the summarization capability should also enable them to replace the use of Gensim with another library or with the use of their own custom trained models if desired down the road. Describe how Contoso should deploy the summarization service so that these requirements are met? Can they deploy a predictive web service to Azure Machine Learning service that does not utilize an external model (as in the case with Gensim) or would support an unsupervised approach (such as clustering)?

    Azure Machine Learning service can be used to deploy web services that do not have a model. While the API used to perform the deployment requires a model argument, the argument can refer to any file, and it does not require the use of the file during the web service runtime. Therefore, Contoso could deploy a web service that uses Gensim to perform summarization.

_Captions, tags and "reading" images_

1. How would you recommend Contoso implement support for automatically creating captions for the claim photos? Similarly, how would they automatically generate tags? Would this require you to build a custom AI model is there a pre-built AI service you could use?

    For both creating captions and the generation of tags, Contoso should use the analyze feature of the Computer Vision API from Cognitive Services.

2. Describe the flow of processing of an image as input; to what value is returned by each component in your proposed solution for captioning and tagging images?

    When using the Computer Vision API, either the binary image data or a URL pointing to a publicly accessible image can be supplied. The return value of Computer Vision API is a JSON document that includes the requested fields (such as captions and tags).

     An example of such as JSON response document is as follows:

    ```json
    {'categories': [{'name': 'others_', 'score': 0.39453125},
    {'name': 'trans_car', 'score': 0.44140625}],
    'color': {'accentColor': '895D42',
    'dominantColorBackground': 'White',
    'dominantColorForeground': 'White',
    'dominantColors': ['White'],
    'isBwImg': False},
    'description': {'captions': [{'confidence': 0.9485308427051494,
        'text': 'a truck is parked on the side of a road'}],
    'tags': ['outdoor',
    'road',
    'truck',
    'car',
    'traffic']},
    'metadata': {'format': 'Jpeg', 'height': 1080, 'width': 1920},
    'requestId': '2236f0b9-044f-415f-b772-a9a4ce15728d',
    'tags': [{'confidence': 0.9950141310691833, 'name': 'outdoor'},
    {'confidence': 0.9936342239379883, 'name': 'road'},
    {'confidence': 0.981715738773346, 'name': 'truck'},
    {'confidence': 0.749627411365509, 'name': 'transport'},
    {'confidence': 0.16133838891983032, 'name': 'trailer'}]}

    ```

3. How would you recommend Contoso implement support for "reading" any text that appears within an image, so it could be searched later? Would this require you to build a custom AI model? Is there a pre-built AI service you could use?

    When attempting to extract text from an image, Contoso could use the OCR feature of the Computer Vision API.

4. Describe the flow of processing of an image as input, to what value returned by each component in your proposed solution for "reading" images.

    When using the Computer Vision API, either the binary image data or a URL pointing to a publicly accessible image can be supplied. The return value of Computer Vision API for the OCR feature is a JSON document, which includes a collection of bounding boxes that contain the text recognized from the image.

     An example of such as JSON response document is as follows:

    ```json
    {
        'language': 'en',
        'orientation': 'Up',
        'regions': [
            {
                'boundingBox': '365,127,937,78',
                'lines': [
                    {
                        'boundingBox': '1028,127,274,49',
                        'words': [
                            {
                                'boundingBox': '1028,141,184,35',
                                'text': 'POLICE'
                            }
                        ]
                    },
                    {
                        'boundingBox': '365,171,318,34',
                        'words': [
                            {
                                'boundingBox': '365,171,318,34',
                                'text': 'EMERGENCY'
                            }
                        ]
                    }
                ]
            }
        ],
        'textAngle': 0.0
    }
    ```

_Enabling search_

1. What service would you recommend Contoso use to enable greater searchability over the claim data, inclusive of the new data fields created by your text processing and image processing components?

    Contoso should use Azure Search to create an Index for the claim data as it enters their system and is augmented by the results of the text and image processing components.

2. Would they be able to keep their claims data in the existing database and layer in this search capability? If so, explain how.

    Yes, the data in the Azure Search index would augment the data already stored in their SQL Database. The data in the Azure Search index would tie back to the data in SQL Database via values used as the primary key in the SQL Database (such as the claim ID, image ID, attachment ID, etc.).

## Checklist of preferred objection handling

1. We are skeptical about all the hype surrounding these "AI" solutions. It's hard to know what is feasible versus what is not possible with today's technology and Azure.

    While it is true that there is a lot of hype around AI, the ability to deploy solutions that use data, machine learning, and deep learning to create an application with "AI" capabilities is real and is possible in Azure. Azure provides a wide range of services to address the needs of AI from pre-built AI capabilities in Cognitive Services to services that help you to build, train, and deploy your custom AI capabilities using the Azure Machine Learning service and other services from the Microsoft AI stack.

2. We know that are both pre-built AI and custom AI options. We are confused as to when to choose one over the other.

    You should consider the pre-built AI options first; however, if you rule them out because they are not fitting your requirements,  then you should explore the custom AI options. The advantage of pre-built AI options like Cognitive Services is that the models they use under the covers do not need to be trained by you, and you do not need to have the data to train them as a pre-requisite.

3. We expect some part of our solution would require deep learning; do you have any prescriptive guidance on how we might choose between investing to learn and use TensorFlow or the Microsoft Cognitive Toolkit (CNTK)?

    Both TensorFlow and the Microsoft Cognitive Toolkit solve similar problems and have been used successfully by many companies for deep learning. At present, it appears that TensorFlow has a much larger community base and interest level, which can be measured simply by the number of stars it has in its GitHub project (which is an order of magnitude larger than that of the Microsoft Cognitive Toolkit). The size of the community means that is likely you will more easily find help online for issues with TensorFlow versus the Microsoft Cognitive Toolkit, which is why it may be a good reason to start with TensorFlow.

## Customer quote (to be read back to the attendees at the end)

"We are excited by the possibilities made real when we use AI to amplify the capabilities of our agents."

Francine Fischer, CIO of Contoso Ltd.
-->

![Microsoft Cloud Workshop](https://github.com/Microsoft/MCW-Template-Cloud-Workshop/raw/master/Media/ms-cloud-workshop.png "Microsoft Cloud Workshop")

<div class="MCWHeader1">
Cognitive Services と深層学習
</div>

<div class="MCWHeader2">
ホワイトボード設計セッション トレーナー用ガイド
</div>

<div class="MCWHeader3">
2019 年 12 月
</div>

このドキュメントに記載されている情報 (URL や他のインターネット Web サイト参照を含む) は、将来予告なしに変更することがあります。別途記載されていない場合、このソフトウェアおよび関連するドキュメントで使用している会社、組織、製品、ドメイン名、電子メール アドレス、ロゴ、人物、場所、出来事などの名称は架空のものです。実在する商品名、団体名、個人名などとは一切関係ありません。お客様ご自身の責任において、適用されるすべての著作権関連法規に従ったご使用をお願いいたします。著作権法による制限に関係なく、マイクロソフトの書面による許可なしに、このドキュメントの一部または全部を複製したり、検索システムに保存または登録したり、別の形式に変換したりすることは、手段、目的を問わず禁じられています。ここでいう手段とは、複写や記録など、電子的、または物理的なすべての手段を含みます。

マイクロソフトは、このドキュメントに記載されている内容に関し、特許、特許申請、商標、著作権、またはその他の無体財産権を有する場合があります。別途マイクロソフトのライセンス契約上に明示の規定のない限り、このドキュメントはこれらの特許、商標、著作権、またはその他の知的財産権に関する権利をお客様に許諾するものではありません。

製造元名、製品名、URL は、情報提供のみを目的としており、これらの製造元またはマイクロソフトのテクノロジを搭載した製品の使用について、マイクロソフトは、明示的、黙示的、または法令によるいかなる表明も保証もいたしません。製造元または製品に対する言及は、マイクロソフトが当該製造元または製品を推奨していることを示唆するものではありません。掲載されているリンクは、外部サイトへのものである場合があります。これらのサイトはマイクロソフトの管理下にあるものではなく、リンク先のサイトのコンテンツ、リンク先のサイトに含まれているリンク、または当該サイトの変更や更新について、マイクロソフトは一切責任を負いません。リンク先のサイトから受信した Web キャストまたはその他の形式での通信について、マイクロソフトは責任を負いません。マイクロソフトは受講者の便宜を図る目的でのみ、これらのリンクを提供します。また、リンクの掲載は、マイクロソフトが当該サイトまたは当該サイトに掲載されている製品を推奨していることを示唆するものではありません。

© 2019 Microsoft Corporation. All rights reserved.


Microsoft および <https://www.microsoft.com/en-us/legal/intellectualproperty/Trademarks/Usage/General.aspx> (英語) に掲載されているその他の商標は、マイクロソフト グループ各社の商標です。その他すべての商標は、その所有者に帰属します。

**目次**

<!-- TOC -->

- [トレーナー情報](#トレーナー情報)
  - [トレーナーの役割](#トレーナーの役割)
  - [ホワイトボード設計セッションの流れ](#ホワイトボード設計セッションの流れ)
  - [ホワイトボード設計セッション開始前: 準備について](#ホワイトボード設計セッション開始前:-準備について)
  - [ホワイトボード設計セッション進行中: ホワイトボード設計セッションの効果を高めるためのヒント](#ホワイトボード設計セッション進行中:-ホワイトボード設計セッションの効果を高めるためのヒント)
- [Cognitive Services と深層学習ホワイトボード設計セッション生徒用ガイド](#cognitive-services-とディープ-ラーニングホワイトボード設計セッション生徒用ガイド)
  - [概要と学習の目的](#概要と学習の目的)
  - [ステップ 1: 顧客事例の確認](#ステップ-1:-顧客事例の確認)
    - [顧客の状況](#顧客の状況)
    - [顧客のニーズ](#顧客のニーズ)
    - [顧客の反論](#顧客の反論)
    - [一般的なシナリオのインフォグラフィック](#一般的なシナリオのインフォグラフィック)
  - [ステップ 2: 概念実証ソリューションの設計](#ステップ-2:-概念実証ソリューションの設計)
  - [ステップ 3: ソリューションのプレゼンテーション](#ステップ-3:-ソリューションのプレゼンテーション)
  - [まとめ](#まとめ)
  - [参考資料](#参考資料)
- [Cognitive Services と深層学習ホワイトボード設計セッション トレーナー用ガイド](#cognitive-services-とディープ-ラーニングホワイトボード設計セッション-トレーナー用ガイド)
  - [ステップ 1: 顧客事例の確認](#ステップ-1:-顧客事例の確認-1)
  - [ステップ 2: 概念実証ソリューションの設計](#ステップ-2:-概念実証ソリューションの設計-1)
  - [ステップ 3: ソリューションのプレゼンテーション](#ステップ-3:-ソリューションのプレゼンテーション-1)
  - [まとめ](#まとめ-1)
  - [想定される顧客担当者](#想定される顧客担当者)
  - [想定されるソリューション](#想定されるソリューション)
  - [想定される反論への対応のチェックリスト](#想定される反論への対応のチェックリスト)
  - [顧客の声 (最後に参加者にもう一度読んでいただく)](#顧客の声-(最後に参加者にもう一度読んでいただく))

<!-- /TOC -->

# トレーナー情報<a name="トレーナー情報"></a>

お忙しい中、トレーナーとしてホワイトボード設計セッションにお力添えいただきありがとうございます。

## トレーナーの役割<a name="トレーナーの役割"></a>

トレーナーには以下のことが求められます。

- 学習を安全に行える環境を作成すること。

- 参加者の思考を促すこと。

- 参加者を学習プロセスに積極的に参加させること。

- 学習プロセスを管理すること (時間を守る、トピックに沿う、参加者のメリットになるように調整する)。

- 個々の参加者が確実に理解できるようにすること。

- 参加者全員をまとめること。

- 学習プロセスに関連する知見や経験を提示すること。

- ホワイトボード設計セッションの議論を効果的にリードすること。

- 参加者の成果物の品質と適切であるかどうかを監督すること。

- フィードバック プロセスを効果的にリードすること。

## ホワイトボード設計セッションの流れ<a name="ホワイトボード設計セッションの流れ"></a>

各ホワイトボード設計セッションは以下の手順で進められます。

**ステップ 1: 顧客事例の確認 (15 分)**

**成果**

顧客のニーズを分析する。

- 顧客の背景、状況、ニーズ、技術的要件

- 顧客の現在のインフラストラクチャとアーキテクチャ

- 想定される問題、反論、障害

**ステップ 2: 概念実証ソリューションの設計 (60 分)**

**成果**

ソリューションを設計し、15 分の講義形式で提供先の顧客の担当者に行うソリューションのプレゼンテーションに向けて準備する。

- 提案先の顧客の担当者を把握します。

- ソリューションで対応する顧客のニーズを把握します。

- ソリューションを設計し、図示します。

- ソリューションのプレゼンテーションに向けて準備します。

**ステップ 3: ソリューションのプレゼンテーション (30 分)**

**成果**

顧客に向けてソリューションのプレゼンテーションを行う。

- ソリューションのプレゼンテーションを行います。

- 顧客からの反論に対応します。

- フィードバックを受けます。

**まとめ (15 分)**

- 採用されたソリューションを再検討します。

## ホワイトボード設計セッション開始前: 準備について<a name="ホワイトボード設計セッション開始前:-準備について"></a>

ホワイトボード設計セッションを開始する前に、以下の準備を行います。

- 生徒用ガイド (顧客事例を含む) とトレーナー用ガイドを熟読します。

- すべてのキー ポイントと作業についてよく理解します。

- 重点を置くポイント、参加者から引き出したい質問、伝え方を計画し、質問に答えられるように準備します。

- ホワイトボード設計セッションを開始する前に顧客事例について検討し、アイデアをさらに掘り出します。

- 後で利用できるようにメモを取ります。

## ホワイトボード設計セッション進行中: ホワイトボード設計セッションの効果を高めるためのヒント<a name="ホワイトボード設計セッション進行中:-ホワイトボード設計セッションの効果を高めるためのヒント"></a>

**トレーナー用ガイド**を参照して、トピックに沿って進めながらタイミングを計ります。

ホワイトボード設計セッションの**詳細をすべて覚えることはありません**。

参加者が作業を行っている間に、**その先を見通して内容を思い出して**みましょう。

- 必要に応じて**作業とホワイトボード設計セッションのペース**を調整して、プレゼンテーション、フィードバック、共有の時間を確保します。

- 自身の経験から**例、注意点、筋書きを追加**します。注意点を明確化し効果的に伝えられるような筋書きを考えましょう。

- **「一時退避所」を設けて**、ホワイトボード設計セッションの範囲外の問題や疑問が発生したらいったん保留し、後で回答できるようにします。このような問題を解決する方法を決めておくと、トピックから脱線することなく対応することができます。

**セッションを楽しみましょう**。全員で楽しむように参加者に働きかけます。

**参加者に積極的な参加を促します。** 自身の知識を話すときにも、常に参加者の積極的な参加を促しましょう。

**参加者に質問を投げかけて**、グループが積極的に学習プロセスに参加するようにします。

可能な限り **最初に質問する** ようにします。トピックの内容に入る前に、そのトピックに関する参加者の意見や経験を把握します。最初に質問すると、参加者の知識や経験のレベルを評価できるうえ、参加者がトレーナーの意見に対してオープンに対応できます。

**回答を待ちます**。「(○○の) 経験は?」といった質問を投げかけた後は、答えが返ってくるまで待ちます。多少の沈黙が生じてもかまいません。慌ててトレーナーが沈黙を破ると、参加者は積極的な参加を求められているわけではないと感じ、受身の姿勢になりがちです。参加者に考えるきっかけを与え、回答がないようなら再度質問を繰り返しましょう。そうすればたいていは回答が得られます。

# Cognitive Services と深層学習ホワイトボード設計セッション生徒用ガイド<a name="cognitive-services-とディープ-ラーニングホワイトボード設計セッション生徒用ガイド"></a>

## 概要と学習の目的<a name="概要と学習の目的"></a>

このホワイトボード設計セッションでは、各種 Cognitive Services として提供されている事前構築済みの人工知能 (AI) と Azure Machine Learning サービスで構築およびデプロイされたカスタム AI サービスの両方を組み合わせたソリューションをグループで設計します。テキスト分析パイプラインの設計と実装を通じて、非構造化テキスト データを処理するインテリジェントなソリューションを作成する方法を学びます。テキスト データの分類に使用されるリカレント ニューラル ネットワークを使用して二項分類器を構築する方法、Azure Machine Learning サービスを使用して複数の種類の予測サービスをデプロイする方法、Cognitive Services の Computer Vision API および Text Analytics API と統合する方法を習得できます。

このホワイトボード設計セッションを修了すると、Azure Machine Learning サービスと Cognitive Services を利用したソリューションを設計するスキルが向上します。

## ステップ 1: 顧客事例の確認<a name="ステップ-1:-顧客事例の確認"></a>

**成果**

顧客のニーズを分析する。

時間: 15 分

指示: セッション参加者全員が集まり、進行役または SME が顧客事例の概要と技術的なヒントを提示します。

1. 自班の参加者とトレーナーが集まります。

2. 生徒用ガイドのステップ 1 ～ 3 の指示をすべて読みます。

3. 班全体で下記の顧客事例を確認します。

### 顧客の状況<a name="顧客の状況"></a>

Contoso Ltd は米国に本社を置く大企業で、米国の一般消費者向けに保険商品を提供しています。同社の商品には傷害健康保険、生命保険、旅行保険、火災保険、自動車保険などがあります。

Contoso では自社保険商品用の次世代プラットフォームの構築を検討しており、その中でも特にクレーム処理に重点的に取り組みたいと考えています。現在、同社では顧客からのクレームを Web サイト、モバイル アプリ、エージェントへの相談により受け付けています。

クレームには以下のような情報が含まれます。

- 保険契約者の情報 (連絡先情報や保険証券番号など)

- クレームの内容を表すフリー テキストの回答 (事故の詳細、その影響、発生時の状況)

- クレームの説明を補完する写真 (事故発生前の保険対象の写真、損害を受けたり盗難に遭った物の写真など)

エージェント (Contoso の従業員や請負業者) がクレーム処理を行う際、提出された個々のクレームの内容をエージェントが読んで処理するのに時間がかかる、しばらくしてからクレームに返信するときに特定のクレーム成果物を見つけるのが難しいなど、大幅なコスト上昇につながる問題が複数あります。個々のクレームはデータベースに格納されており、フリー テキストの回答やそれを補完する写真などを含むクレームの詳細はわかりづらい添付ファイルとして検索できない形で保管されています。このため、エージェントがクレーム番号や保険契約者の連絡先情報を基にクレームを特定してから手作業で添付ファイルを読み取らなければならないことも珍しくありません。

また、一般的な課題の一部を自動化して解決したいと考えています。CIO の Francine Fischer は、2 つの課題群を AI で解決し、エージェントの能力を強化したいと考えています。

1 つ目の課題群は、フリー テキストの回答への対応に関するものです。最初の課題は、テキストから判断してそれぞれのクレームが火災保険、あるいは自動車保険に関するものかを自動的に分類することです。この分類はクレームの概要に表示されるため、クレームの内容が火災保険だけに関するものなのか、自動車保険だけに関するものなのか、またはその両方を含むものなのかをエージェントがすばやく判断できます。

2 つ目の課題は、クレームのテキストに感情分析を適用できるかどうかをテストすることです。顧客の大部分は冷静 (中立的な感情) であるか多少不機嫌 (比較的悪い感情) であり、クレームのテキストに悪い感情が含まれている場合は状況が特に深刻で、エージェントが迅速に確認することを保証しなければならない場合もあります。

3 つ目の課題は、長文のフリー テキストがあるということです。エージェントが複数のクレームを扱っているときに、探しているクレームの内容がどのようなものだったかを思い出すことが難しい場合があります。そこで Contoso は、長文のクレームを 30 ワード程度の文に要約する自動要約機能をテストしたいと考えています。エージェントは、クレームの処理を再開するときにこの要約を読んで大まかな内容をつかめば、全文を読まなくてもすばやく思い出すことができます。

次の課題群は、提出された写真から情報を抽出するエージェントの能力を強化し、検索の機能を向上させることです。1 つ目の課題は、写真の内容を示すキャプションを自動生成することです。2 つ目は、写真の内容を示すタグを自動で適用することです。3 つ目は、写真の中に含まれるあらゆるテキストを抽出することです。これらの課題を解決すると、エージェントが入力する必要があるデータの量を削減しながら、同時に写真が検索しやすくなります。

最後に、写真から抽出された情報を整理し、フリー テキストの回答の処理結果と併せてソリューションと連携させ、簡単に検索できるようにすると共に新しいクレーム情報の取得に対応して常に最新の状態になるようにします。

この大きな目標に向けた第一歩として、上記のすべてを自動化するインテリジェントなソリューションの概念実証版 (PoC) を構築します。同社では、既に Azure で実行しているクレーム提出ソリューション (クレーム提出は Web App で、クレームの保管は SQL Database で構築) の PoC 版を作成したいと考えています。上記の課題は AI、機械学習、ディープ ラーニングを活用すれば解決できると予想しており、これらのテクノロジでどの程度まで実現できるかを PoC 版の構築を通じて把握します。

### 顧客のニーズ<a name="顧客のニーズ"></a>

1. フリー テキストの回答からは有益な情報が大量に得られるが、長文のものもあるため、エージェントが読み飛ばしてきわめて重要な詳細を見落としたり、クレームに返信するときにそのクレームを探すのに長い時間を要したりすることがある。これを自動化できるかどうかはまだ不明だが、標準化されたプロセスでクレーム内の主なエンティティを認識し、エージェントが容易に確認できるように独立したリストに抽出して、クレームの文脈に含まれるエンティティを簡単に見られるようにしたい。

2. 写真を「見て」、その内容を説明し、キーワードを含むタグを付与して、後でその写真が必要なときに容易に探して参照できるようにするソリューションを求めている。

3. エージェントを廃止するわけではなく、エージェントの能力を向上させてクレーム処理能力を強化したい。エージェントと同じ処理を実行できるソリューションを求めている。

### 顧客の反論<a name="顧客の反論"></a>

1. このような「AI」ソリューションに関する過大な評価には疑問がある。現在のテクノロジと Azure で実現可能なことと不可能なことを区別するのが難しい。

2. 事前構築済みの AI を使用する方法とカスタム AI を使用する方法があるが、そのどちらを選べばよいかわかりづらい。

3. ソリューションの一部にはディープ ラーニングの使用が必要になると予想している。TensorFlow や Microsoft Cognitive Toolkit (CNTK) の習得と使用に投資すべきか否かの判断基準となるガイドはないか。

### 一般的なシナリオのインフォグラフィック<a name="一般的なシナリオのインフォグラフィック"></a>

![テキストの分類モデルのトレーニングの図では、ドキュメントのラベル (Document Labels) から教師あり ML/DL アルゴリズム (Supervised ML or DL Algorithm) に、そこから分類モデル (Classification Model) に矢印が伸びる。ドキュメント (Documents) からテキスト正規化 (Text Normalization) に、そこから特徴抽出 (Feature Extraction) に、そこから教師あり ML/DL アルゴリズム (Supervised ML or DL Algorithm) に矢印が伸びる。ベクトル (Vectors) から単語一覧とそのパーセンテージの表に矢印が伸びる。](images/Whiteboarddesignsessiontrainerguide-CognitiveServicesanddeeplearningimages/media/image2.png "テキストの分類モデルのトレーニングの図")

![テキストの分類予測の図では、ドキュメント (Documents) からテキスト正規化 (Text Normalization) に、そこから特徴抽出 (Feature Extraction) に、そこから分類モデル (Classification Model) に、そこからドキュメントのラベル (Document Labels) に矢印が伸びる。ベクトル (Vectors) から単語一覧とそのパーセンテージの表に矢印が伸びる。](images/Whiteboarddesignsessiontrainerguide-CognitiveServicesanddeeplearningimages/media/image3.png "テキストの分類予測の図")

## ステップ 2: 概念実証ソリューションの設計<a name="ステップ-2:-概念実証ソリューションの設計"></a>

**成果**

ソリューションを設計し、15 分の講義形式で提供先の顧客の担当者に行うソリューションのプレゼンテーションに向けて準備する。

時間: 60 分

**ビジネス ニーズ**

指示: 班の参加者全員で以下の質問に回答し、フリップ チャートに回答の一覧を記載します。

1. ソリューションを提案する相手は? 提案先の顧客の担当者は? 意思決定者は?

2. このソリューションで解決が必要な顧客のビジネス ニーズは?

**設計**

指示: 班の参加者全員でフリップ チャートに記載された以下の質問に回答します。

_アーキテクチャの概要_

1. 詳細には触れずに (詳細については後のセクションで扱います)、クレームのテキスト データや写真を処理し検索可能にするための大まかな要件に対応する初期構想を図示します。この図の内容は、進行に合わせて修正します。

_クレーム テキスト データの分類_

1. このようなテキスト分析モデルのトレーニングを実施する場合の一般的な手順、および分類などのタスクを実行するために必要なテキスト データを準備する方法を把握します。

2. モデルのトレーニングに必要なデータの種類を把握します。

3. Contoso が機械学習でテキストを処理する場合の代表的な手法を理解したいと考えているかどうかを確認します。また、クレーム テキスト データでよく見られる長文の説明的なテキストを処理する際に推奨される手法があるかどうかを把握します。

4. Contoso では分類アルゴリズムがこの問題に使用されることを理解していて、火災保険と自動車保険の分類に使用するテキストに対してディープ ニューラル ネットワーク (DNN) をトレーニングできないかという質問を同社から受けました。実際に DNN を使用できるかどうか検討します。

5. このシナリオでは、Contoso は TensorFlow の使用に興味を示していますが、急に使用を開始する場合の煩雑さについて憂慮しています。同社はまず Keras の比較的簡単なフレームワークを使用し、その後充実した機能を備える TensorFlow にステップ アップすることを検討しています。TensorFlow 互換モデルを構築し、チームの準備が整ったら「卒業」して TensorFlow に移行することが可能かどうか検討します。

6. このような分類を実行する LSTM リカレント ニューラル ネットワークについて理解します。展開された LSTM ネットワークの単一層のスニペット、およびネットワークの最後のステップで出力される二項分類の結果を提示します。

7. Keras で LSTM リカレント ニューラル ネットワークを使用して分類器をトレーニングすると仮定して、図のとおりにネットワークを構築するためのコードを擬似コード形式で作成します。

8. 次に、最適化手法と損失関数を定義する方法、およびベクトル化されたデータやラベルにモデルを適合させる方法の擬似コードを作成します。

9. トレーニング済みモデルが得られたら、そのモデルを特定のクレーム テキストのクラスの予測に使用する方法の擬似コードを作成します。どのような予測結果が得られるか、値をどのように解釈するかを理解します。

10. トレーニング済みモデルをデプロイする方法、および Web サービスとしてソリューションの中に統合する方法を大まかに説明します。

_フリー テキストの感情の認識_

1. クレームに対するフリー テキストの回答の感情認識を Contoso に推奨する方法を検討します。カスタム AI モデルが必要かどうか、この課題に使用できる事前構成済みの AI サービスの有無についても検討します。

2. 提案するソリューションにおけるセンチメント スコアの値の範囲、およびその値をどのように解釈するかを決定します。

_クレーム テキストの要約_

1. Contoso チームは、要約関数が実装された Gensim という Python ライブラリの名前は聞いたことがありました。この関数は、テキストを入力すると要約を指定した長さで抽出します。まずは、Gensim を使用してこの要約関数を PoC 版に実装します。しかし、後にデプロイする要約機能では Gensim 以外のライブラリを使用し、将来的には独自開発のカスタマイズされたトレーニング済みモデルの使用も検討しています。要件を満たす要約サービスをデプロイする方法を説明します。

2. 外部モデル (Gensim など) を使用していない Azure Machine Learning サービスに予測 Web サービスをデプロイできるか、および教師なし学習をサポートするかどうかを検討します。

_画像のキャプション、タグ、「読み取り」_

1. クレームの写真のキャプションを自動生成する機能の実装を推奨する方法を検討します。同様に、タグの自動生成機能についても検討します。カスタム AI モデルが必要かどうか、この課題に使用できる事前構成済みの AI サービスの有無についても検討します。

2. 画像が入力されたときの処理の流れ、およびチームが提案した、画像のキャプション生成とタグ付与を行うソリューションの各コンポーネントが返す値を説明します。

3. 画像内のあらゆるテキストを「読み取り」、後から検索できるようにする機能の実装を Contoso に推奨する方法を検討します。カスタム AI モデルが必要かどうか、この課題に使用できる事前構成済みの AI サービスの有無についても検討します。

4. 画像が入力されたときの処理の流れ、およびチームが提案した画像「読み取り」ソリューションの各コンポーネントが返す値を説明します。

_検索の機能向上_

1. テキスト処理や画像処理のコンポーネントで作成された新規データ フィールドを含むクレーム データの検索の機能を向上させるサービスについて、どのサービスを Contoso に推奨するかを検討します。

2. クレーム データを既存のデータベースで維持しながらこの検索機能を追加することができるかどうかを確認します。可能であるならば、その方法を説明します。

**準備**

指示: 班の参加者全員と以下を行います。

1. 提案したソリューションでは解決されない顧客のニーズを把握します。

2. ソリューションのメリットを把握します。

3. 顧客の反論に対応する方法を検討します。

15 分の講義形式で顧客に行うソリューションのプレゼンテーションに向けて準備します。

## ステップ 3: ソリューションのプレゼンテーション<a name="ステップ-3:-ソリューションのプレゼンテーション"></a>

**成果**

15 分の講義形式で提供先の顧客の担当者にソリューションのプレゼンテーションを行う。

時間: 30 分

**プレゼンテーション**

指示:

1. 他の班と組みます。

2. 一方の班はマイクロソフト チームを、もう一方の班は顧客を担当します。

3. マイクロソフト チームは、提案するソリューションのプレゼンテーションを顧客に向けて行います。

4. 顧客側は、反論リストの中からいずれかの反論を行います。

5. マイクロソフト チームは反論に対応します。

6. 顧客側はマイクロソフト チームにフィードバックを提供します。

7. 役割を入れ替えてステップ 2 ～ 6 を繰り返します。

## まとめ<a name="まとめ"></a>

時間: 15 分

指示: 各班が集まり、進行役や SME が事例に適したソリューションを発表します。 

## 参考資料<a name="参考資料"></a>

|                                                       |                                                                                                   |
| ----------------------------------------------------- | ------------------------------------------------------------------------------------------------- |
| **説明**                                       | **リンク**                                                                                         |
| Azure Machine Learning サービス                        | <https://docs.microsoft.com/ja-jp/azure/machine-learning/overview-what-is-azure-ml>       |  |
| Web サービスのデプロイ                                | <https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-deploy-and-where> |
| Keras の概要                                   | <https://keras.io/> (英語) |
| TensorFlow の概要                               | <https://www.tensorflow.org/> (英語) |
| 単語出現頻度 - 逆文書頻度 (TF-IDF) ベクトル化 | <https://ja.wikipedia.org/wiki/Tf-idf> |
| GloVe: Global Vectors for Word Representation | <https://nlp.stanford.edu/projects/glove/> (英語)  |
| 研究論文: "GloVe: Global Vectors for Word Representation" | <https://nlp.stanford.edu/pubs/glove.pdf> (英語)  |
| Word2vec 単語埋め込み | <https://en.wikipedia.org/wiki/Word2vec> (英語)  |
| Cognitive Service の Computer Vision API の概要 | <https://docs.microsoft.com/ja-jp/azure/cognitive-services/computer-vision/home>                  |
| Cognitive Service の Text Analytics API の概要  | <https://docs.microsoft.com/ja-jp/azure/cognitive-services/text-analytics/overview>               |

# Cognitive Services と深層学習ホワイトボード設計セッション トレーナー用ガイド<a name="cognitive-services-とディープ-ラーニングホワイトボード設計セッション-トレーナー用ガイド"></a>

## ステップ 1: 顧客事例の確認<a name="ステップ-1:-顧客事例の確認-1"></a>

- 自班の参加者と対面し、トレーナーとして自己紹介します。

- 「この顧客事例について不明な点を挙げてください」と問いかけます。

- ホワイトボード設計セッションのステップと時間を大まかに確認します。

- これで準備完了です。自班の参加者にセッションを始めていただきます。

## ステップ 2: 概念実証ソリューションの設計<a name="ステップ-2:-概念実証ソリューションの設計-1"></a>

- 各ステップを時間どおりに進められるように自班の参加者と確認します。

- ビジネス ニーズや設計に関する参加者からの回答にフィードバックを返します。

  - 参加者が自身で答えにたどり着くように導く質問を、最初に投げかけるようにします。

- 顧客の反論への対応に対してフィードバックを返します。

  - 参加者が自身で答えにたどり着くように導く質問を、最初に投げかけるようにします。

## ステップ 3: ソリューションのプレゼンテーション<a name="ステップ-3:-ソリューションのプレゼンテーション-1"></a>

- ステップ 3 を始める前に、自班と組む相手の班を決めます。

- 1 巡目にプレゼンテーションを行う班と顧客側を演じる班を割り当てます。

- プレゼンテーション チームは、顧客チームにソリューションのプレゼンテーションを行います。

  - 顧客チームはプレゼンテーション チームに反論を 1 つ提示し、プレゼンテーション チームはこれに対応します。

  - プレゼンテーションから反論、フィードバックの提供までを 15 分以内にまとめます。

  - 必要に応じてトレーナーもフィードバックを提供します。

## まとめ<a name="まとめ-1"></a>

- 参加者は大きなセッション グループに再び合流し、ソリューションに関する以下の想定について進行役や SME から説明を受けます。

## 想定される顧客担当者<a name="想定される顧客担当者"></a>

Francine Fischer (Contoso Ltd. CIO)

主な対象はビジネスおよびテクノロジの意思決定者となります。今回の例では、分析担当ディレクターなどがこれに含まれます。通常は、最高情報責任者 (CIO) に報告を行うインフラストラクチャ管理者、アプリケーションのスポンサー (事業部門担当 \[LOB\] バイス プレジデント \[VP\] や最高マーケティング責任者 \[CMO\])、アプリケーションのスポンサーに報告を行う事業部門の IT 担当者や開発者が対象となります。

## 想定されるソリューション<a name="想定されるソリューション"></a>

_アーキテクチャの概要_

1. 詳細には触れずに (詳細については後のセクションで扱います)、クレームのテキスト データや写真を処理し検索可能にするための大まかな要件に対応する初期構想を図示します。この図の内容は、進行に合わせて修正します。

マイクロソフトと協議した結果、Contoso チームは Azure で PoC ソリューションを設計することを決めました。Contoso が既に Azure で実行しているクレーム提出用 Web アプリと SQL データベースは、引き続き使用します。Azure Functions のシーケンスを呼び出すと、クレーム処理強化パイプラインを構築できます。この中では、AI を活用したさまざまなサービスが呼び出されて連携します。

 ![ソリューションのアーキテクチャの概要の図では、クレームから矢印が始まり Jupyter ノートブックに伸びる。Jupyter から Computer Vision、Text Analytics、およびクレーム テキストの処理に使用される分類サービスと要約サービスを含むコンテナー化されたサービスに矢印が伸びる。](images/Whiteboarddesignsessiontrainerguide-CognitiveServicesanddeeplearningimages/media/image4.jpg "ソリューションのアーキテクチャの概要")

クレーム画像処理関数からは Cognitive Service の Computer Vision が呼び出され、対象となるクレームの画像からキャプションの生成とタグの付与が自動的に行われます。クレーム テキストの処理は、Cognitive Services の形で提供される事前構築済みの AI と Azure ML サービスの形で提供されるカスタム AI を組み合わせて実行されます。クレーム テキストの処理に使用されるモデルは、Azure Databricks ノートブックでトレーニングされます。これらのモデルは、Azure Machine Learning Service Python SDK を使用して Azure Databricks から直接デプロイされます。Azure Functions は、分類や要約を行う AI サービスの呼び出しを調整します。これらのサービスはコンテナー化された　Web サービスとして Azure Container Service で実行され、一方で Text Analytics API は直接呼び出されて各クレーム テキストのセンチメント スコアを返します。

 ![クレーム画像処理の図では、関数 (クレーム テキスト処理) から感情、分類、要約、Text Analytics、コンテナー化されたサービス (分類サービスと要約サービスを含む) に矢印が伸びる。](images/Whiteboarddesignsessiontrainerguide-CognitiveServicesanddeeplearningimages/media/image5.png "クレーム画像処理の図")

クレーム処理がすべて完了したら、最後に実行される Azure Function でクレーム ドキュメント全文が Azure Search に挿入されます。挿入されるドキュメントにはクレーム番号がフィールドとして含まれているため、Azure SQL Database のレコード ストアに必ず紐付けられています。

_クレーム テキスト データの分類_

1. このようなテキスト分析モデルのトレーニングを実施する場合の一般的な手順、および分類などのタスクを実行するために必要なテキスト データを準備する方法を把握します。

    ![テキスト分類モデルのトレーニング手順の概要の図では、ドキュメントのラベルから教師あり ML/DL アルゴリズムに、そこから分類モデルに矢印が伸びる。ドキュメントからテキスト正規化に、そこから特徴抽出に、そこから教師あり ML/DL アルゴリズムに矢印が伸びる。](images/Whiteboarddesignsessiontrainerguide-CognitiveServicesanddeeplearningimages/media/image6.png "テキスト分類モデルのトレーニング手順の概要の図")

    上の図のように、一般的なパイプラインはテキストの前処理や正規化から始まります。この手順では、テキストを文や単語のトークンに分割する、単語のスペリングを標準化する、あまりにも一般的な単語 (ストップ ワードと呼ばれる) を削除するなどのタスクを実行します。一般に、この段階の出力はドキュメントの配列で構成される多次元配列で、それぞれに文の配列があり、さらにそれに単語の配列が存在します。次の手順は特徴抽出で、テキスト ドキュメントの数値表現が作成されます。特徴抽出では一意の単語の「ボキャブラリ」が識別され、1 列につき 1 単語の形で出力されます。各行は 1 つのドキュメントを表します。通常、各セルの値はそのドキュメントにおける特定の単語の相対的重要度の測定値で、ボキャブラリの中の特定の単語がドキュメントで使用されていなければ、その列の該当するセルの値は 0 になります。このアプローチは機械学習アルゴリズムに対応していますが、数値配列にもテキストにも不向きです。ディープ ラーニング アルゴリズムはベクトル (または数値配列) を含むテンソルの扱いに適しているため、このアプローチはディープ ラーニング アルゴリズムを使用したテキストの前処理にも有効です。

2. モデルのトレーニングに必要なデータの種類を把握します。

    モデルをトレーニングするには、火災保険または自動車保険というラベルが付与された過去のクレーム テキストが一定量必要です。

3. Contoso が機械学習でテキストを処理する場合の代表的な手法を理解したいと考えているかどうかを確認します。また、クレーム テキスト データでよく見られる長文の説明的なテキストを処理する際に推奨される手法があるかどうかを把握します。

    機械学習モデルには数値データを入力する必要があります。このため、特徴抽出の中でテキストを処理する場合にはテキスト中の単語や文を数値ベクトル表現に変換します。テキスト データのベクトル化には、[単語出現頻度 - 逆文書頻度 (TF-IDF) ベクトル化](https://ja.wikipedia.org/wiki/Tf-idf)や、[Word2vec (英語)](https://en.wikipedia.org/wiki/Word2vec) または [Global Vectors (GloVe) (英語)](https://nlp.stanford.edu/pubs/glove.pdf) といった単語埋め込みを使用するなど、複数のアプローチがあります。 

    TF-IDF のアプローチでは、多くのドキュメントで共通して使用されている単語には低い重要度が、少数のドキュメントで特に頻繁に使用されている単語には高い重要度が与えられます。TF-IDF では、こうしてドキュメント内での関連性を示す重み付けを単語に対して行います。しかし TF-IDF のアプローチには、単語間のセマンティックな類似性が使用されないことをはじめ、欠点もあります。

    埋め込みにより単語や文を表す手法は、NLP の分野では最新技術とされています。DNN で特に広く使用されている単語埋め込みには、Word2vec と GloVe があります。Word2vec と GloVe のいずれも同様の機能を持ちますが、類似性に関するタスクや固有表現の認識では GloVe のほうが優れているとされています。

    クレーム データは記述的なものであるため、このシナリオでは単語のベクトル表現には [nlp.stanford.edu (英語)](https://nlp.stanford.edu/projects/glove/) で提供されているトレーニング済みの GloVe の単語埋め込みを推奨します。

4. Contoso では分類アルゴリズムがこの問題に使用されることを理解していて、火災保険と自動車保険の分類に使用するテキストに対してディープ ニューラル ネットワーク (DNN) をトレーニングできないかという質問を同社から受けました。実際に DNN を使用できるかどうか検討します。

    超短期記憶 (LSTM) リカレント ニューラル ネットワークと呼ばれる種類の DNN を使用できます。この手法は、特に GloVe などの単語埋め込みによる単語のベクトル化と併用すると、テキスト分類問題で良好な結果が得られています。

5. このシナリオでは、Contoso は TensorFlow の使用に興味を示していますが、急に使用を開始する場合の煩雑さについて憂慮しています。同社はまず Keras の比較的簡単なフレームワークを使用し、その後充実した機能を備える TensorFlow にステップ アップすることを検討しています。TensorFlow 互換モデルを構築し、チームの準備が整ったら「卒業」して TensorFlow に移行することが可能かどうか検討します。

    TensorFlow は、ニューラル ネットワークの構築などの機械学習を実行する場合に高い信頼性を持つフレームワークです。Keras ライブラリは TensorFlow の上に構築されていて、ディープ ニューラル ネットワークに実装して容易に使用したり習得したりできる高水準の API が提供され、チュートリアルやサンプルも利用できます。Keras で構築されるモデルは TensorFlow モデルであるため、低水準の TensorFlow API に完全に移行する場合にもモデルを再構築する必要はありません。

6. このような分類を実行する LSTM リカレント ニューラル ネットワークについて理解します。展開された LSTM ネットワークの単一層のスニペット、およびネットワークの最後のステップで出力される二項分類の結果を提示します。

    ![この図は、展開された LSTM ネットワークの単一層のスニペット、およびネットワークの最後のステップで出力される二項分類の結果を示しています.](images/Whiteboarddesignsessiontrainerguide-CognitiveServicesanddeeplearningimages/media/lstm.png "展開された LSTM ネットワーク")

7. Keras で LSTM リカレント ニューラル ネットワークを使用して分類器をトレーニングすると仮定して、図のとおりにネットワークを構築するためのコードを擬似コード形式で作成します。

    ```python
    model = Sequential()

    model.add(embedding_layer)

    model.add(LSTM(100, ..., ...))

    model.add(Dense(2))

    model.add(Activation('sigmoid'))
    ```

8. 次に、最適化手法と損失関数を定義する方法、およびベクトル化されたデータやラベルにモデルを適合させる方法の擬似コードを作成します。

    ```python
    opt = keras.optimizers.Adam(lr = ...)

    model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['accuracy'])

    model.fit(X_train, y_train, epochs = ..., batch_size = ..., validation_data = ...)
    ```

9. トレーニング済みモデルが得られたら、そのモデルを特定のクレーム テキストのクラスの予測に使用する方法の擬似コードを作成します。どのような予測結果が得られるか、値をどのように解釈するかを理解します。

    ```python
    test_claim = ['I crashed my car into a pole.']

    pred = model.predict(test_claim)
    ```

    この予測の出力は信頼度の配列で、ラベルは 0 または 1 で表されます。例:

    ```python
    array([ [0.22, 0.78] ])
    ```

    この例では、1 (「自動車保険のクレーム」) であることが予測され、その信頼度は 78% であることが示されています。

10. トレーニング済みモデルをデプロイする方法、および Web サービスとしてソリューションの中に統合する方法を大まかに説明します。また、使用可能な Azure サービスについて説明します。

     トレーニング済みモデルはファイルに保存されます。その後の手順でこのファイルは Web サービスのコードから読み込まれ、モデル アーキテクチャの再作成とモデルの重み付けに使用されます。Web サービスのコードは、モデルを使用して分類を実行します。このサービスのデプロイには Azure Machine Learning サービスを使用できます。この場合、コンテナーに Web サービスを格納し、そのコンテナーを Azure Container Service にデプロイして、任意の REST クライアントから呼び出すことができます。

_フリー テキストの感情の認識_

1. クレームに対するフリー テキストの回答の感情認識を Contoso に推奨する方法を検討します。この課題ではカスタム AI モデルが必要かどうか、および事前構成済みの AI サービスを使用可能かどうかについても検討します。

    Contoso では、クレーム テキストのセンチメント スコアの出力に Cognitive Services の Text Analytics API を使用します。このため、カスタム モデルの構築やトレーニングは不要で、そのためのデータ要件に従う必要もありません。

2. 提案するソリューションにおけるセンチメント スコアの値の範囲、およびその値をどのように解釈するかを決定します。

    Text Analytics API からは 0 ～ 1 の範囲の数値が返されます。値が 0 に近い場合は非常に強い悪感情、0.5 に近い場合は中立的な感情、1 に近い場合は非常に強い好感を示します。

_クレーム テキストの要約_

1. Contoso チームは、要約関数が実装された Gensim という Python ライブラリの名前は聞いたことがありました。この関数は、テキストを入力すると要約を指定した長さで抽出します。まずは、Gensim を使用してこの要約関数を PoC 版に実装します。しかし、後にデプロイする要約機能では Gensim 以外のライブラリを使用し、将来的には独自開発のカスタマイズされたトレーニング済みモデルの使用も検討しています。要件を満たす要約サービスをデプロイする方法を説明します。外部モデル (Gensim など) を使用していない Azure Machine Learning サービスに予測 Web サービスをデプロイできるか、教師なし学習 (クラスタリングなど) をサポートするかどうかを検討します。

    Azure Machine Learning サービスでは、モデルを持たない Web サービスをデプロイできます。デプロイメントの実行に使用する API にはモデルの引数が必要ですが、この引数は何らかのファイルを参照することが可能で、Web サービス実行中はそのファイルを使用する必要はありません。このため、Contoso では Gensim を使用して要約を実行する Web サービスをデプロイできます。

_画像のキャプション、タグ、「読み取り」_

1. クレームの写真のキャプションを自動生成する機能の実装を推奨する方法を検討します。同様に、タグの自動生成機能についても検討します。この課題ではカスタム AI モデルが必要かどうか、および事前構成済みの AI サービスを使用可能かどうかについても検討します。

    Contoso は、キャプション生成とタグ生成のどちらにも Cognitive Services の Computer Vision API の分析機能を使用します。

2. 画像が入力されたときの処理の流れ、およびチームが提案した、画像のキャプション生成とタグ付与を行うソリューションの各コンポーネントが返す値を説明します。

    Computer Vision API を使用する場合、バイナリ画像データ、またはインターネットからアクセス可能な画像を示す URL のいずれかを指定できます。Computer Vision API から返される値は、必須フィールド (キャプションやタグなど) を含む JSON ドキュメントです。

     JSON 形式の応答ドキュメントの例を次に示します。

    ```json
    {'categories': [{'name': 'others_', 'score': 0.39453125},
    {'name': 'trans_car', 'score': 0.44140625}],
    'color': {'accentColor': '895D42',
    'dominantColorBackground': 'White',
    'dominantColorForeground': 'White',
    'dominantColors': ['White'],
    'isBwImg': False},
    'description': {'captions': [{'confidence': 0.9485308427051494,
        'text': 'a truck is parked on the side of a road'}],
    'tags': ['outdoor',
    'road',
    'truck',
    'car',
    'traffic']},
    'metadata': {'format': 'Jpeg', 'height': 1080, 'width': 1920},
    'requestId': '2236f0b9-044f-415f-b772-a9a4ce15728d',
    'tags': [{'confidence': 0.9950141310691833, 'name': 'outdoor'},
    {'confidence': 0.9936342239379883, 'name': 'road'},
    {'confidence': 0.981715738773346, 'name': 'truck'},
    {'confidence': 0.749627411365509, 'name': 'transport'},
    {'confidence': 0.16133838891983032, 'name': 'trailer'}]}

    ```

3. 画像内のあらゆるテキストを「読み取り」、後から検索できるようにする機能の実装を Contoso に推奨する方法を検討します。カスタム AI モデルが必要かどうか、この課題に使用できる事前構成済みの AI サービスの有無についても検討します。

    Contoso では、画像からのテキスト抽出に Computer Vision API の OCR 機能を使用します。

4. 画像が入力されたときの処理の流れ、およびチームが提案した画像「読み取り」ソリューションの各コンポーネントが返す値を説明します。

    Computer Vision API を使用する場合、バイナリ画像データまたはインターネットからアクセス可能な画像を示す URL のいずれかを指定できます。Computer Vision API の OCR 機能で返される値は、画像から抽出されたテキストを含む境界ボックスの集合を含む JSON ドキュメントです。

     JSON 形式の応答ドキュメントの例を次に示します。

    ```json
    {
        'language': 'en',
        'orientation': 'Up',
        'regions': [
            {
                'boundingBox': '365,127,937,78',
                'lines': [
                    {
                        'boundingBox': '1028,127,274,49',
                        'words': [
                            {
                                'boundingBox': '1028,141,184,35',
                                'text': 'POLICE'
                            }
                        ]
                    },
                    {
                        'boundingBox': '365,171,318,34',
                        'words': [
                            {
                                'boundingBox': '365,171,318,34',
                                'text': 'EMERGENCY'
                            }
                        ]
                    }
                ]
            }
        ],
        'textAngle': 0.0
    }
    ```

_検索の機能向上_

1. テキスト処理や画像処理のコンポーネントで作成された新規データ フィールドを含むクレーム データの検索の機能を向上させるサービスについて、どのサービスを Contoso に推奨するかを検討します。

    クレーム データがシステムに入力されるときに、Azure Search でそのインデックスを作成します。このとき、テキストや画像を処理するコンポーネントの結果が引数として使用されます。

2. クレーム データを既存のデータベースで維持しながらこの検索機能を追加することができるかどうかを確認します。可能であるならば、その方法を説明します。

    Azure Search のインデックスのデータの引数には、既に SQL Database に格納されているデータが使用されます。Azure Search のインデックスのデータは、SQL Database でプライマリ キーとして使用されている値 (クレーム ID、画像 ID、添付ファイル ID など) によって SQL Database のデータに紐付けられます。

## 想定される反論への対応のチェックリスト<a name="想定される反論への対応のチェックリスト"></a>

1. このような「AI」ソリューションに関する過大な評価には疑問がある。現在のテクノロジと Azure で実現可能なことと不可能なことを区別するのが難しい。

    AI に関しては過大評価も少なくありませんが、データ、機械学習、ディープ ラーニングを活用したソリューションをデプロイして「AI」の能力を備えたアプリケーションを作成することは、Azure で実現可能です。Azure では、Cognitive Services の事前構築済みの AI 機能から、Azure Machine Learning サービスやその他のマイクロソフトの AI スタックによるカスタム AI 機能の構築、トレーニング、デプロイの支援まで、AI に関するニーズに対応するサービスを幅広く提供しています。

2. 事前構築済みの AI を使用する方法とカスタム AI を使用する方法があるが、そのどちらを選べばよいかわかりづらい。

    まずは事前構築済みの AI を利用することを検討します。しかし、要件に適合しないためにこれを利用できない場合、カスタム AI の使用を検討します。Cognitive Services などの事前構築済みの AI のメリットは、そのままの状態でモデルを使用できるため自分でトレーニングする必要がなく、トレーニングの前提条件となるデータを用意する必要もありません。

3. TensorFlow や Microsoft Cognitive Toolkit (CNTK) の習得と使用に投資すべきか否かの判断基準となるガイドはないか。

    TensorFlow と Microsoft Cognitive Toolkit のどちらでも同様の問題を解決可能で、ディープ ラーニングの分野で多くの企業が使用して良い結果を得ています。現時点では TensorFlow のほうがコミュニティの規模や関心度の点で大きく上回っています。これは、GitHub プロジェクトで活躍する著名開発者の数からもわかります (Microsoft Cognitive Toolkit と比較すると桁違いに多い)。コミュニティの規模が大きいので、問題が発生した場合に Microsoft Cognitive Toolkit よりも TensorFlow のほうがオンラインでの支援を得やすいため、最初は TensorFlow を使用するほうが良いかもしれません。

## 顧客の声 (最後に参加者にもう一度読んでいただく)<a name="顧客の声-(最後に参加者にもう一度読んでいただく)"></a>

「Contoso では、AI を活用してエージェントの能力を強化するという目標の実現に期待しています」

Francine Fischer (Contoso Ltd. CIO)